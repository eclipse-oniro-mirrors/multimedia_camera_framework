From 2e375188617a146ac9af78ad57b6055444f25086 Mon Sep 17 00:00:00 2001
From: s00888898 <s00888898@notesmail.huawei.com/>
Date: Tue, 25 Feb 2025 10:01:58 +0800
Subject: [PATCH] =?UTF-8?q?TicketNo:AR20250106994028=20Description:?=
 =?UTF-8?q?=E9=AB=98=E6=98=BE=E8=89=B2=E5=9F=9F=E9=9C=80=E6=B1=82=E5=BC=80?=
 =?UTF-8?q?=E5=8F=91=20Team:OTHERS=20Feature=20or=20Bugfix:Feature=20Binar?=
 =?UTF-8?q?y=20Source:NA=20PrivateCode(Yes/No):No?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Change-Id: I2a52c3c8f616d2434bb89ab96354b6e8cf1d66ac
---
 .../src/output/photo_output_napi.cpp          | 195 +++++++++++++++---
 .../camera/src/session/capture_session.cpp    | 149 ++-----------
 .../src/camera_session_moduletest.cpp         |  13 +-
 .../src/avcodec_task_manager_unittest.cpp     |  19 +-
 .../src/moving_photo_video_cache_unittest.cpp |  11 +-
 .../avcodec/src/video_encoder_unittest.cpp    |   9 +-
 .../src/hcamera_service_unittest.cpp          |   3 +-
 .../src/hcapture_session_unittest.cpp         |   9 +-
 .../session/src/capture_session_unittest.cpp  |  95 +++++++++
 .../camera/include/session/capture_session.h  |   3 -
 .../include/output/photo_output_napi.h        |  14 ++
 .../binder/base/include/icapture_session.h    |   2 +-
 .../client/include/hcapture_session_proxy.h   |   2 +-
 .../client/src/hcapture_session_proxy.cpp     |   3 +-
 .../server/src/hcapture_session_stub.cpp      |   3 +-
 .../include/avcodec/avcodec_task_manager.h    |   4 +-
 .../include/avcodec/common/sample_info.h      |   1 +
 .../include/avcodec/video_encoder.h           |   5 +-
 .../camera_service/include/hcapture_session.h |   3 +-
 .../camera_service/include/hstream_operator.h |   5 +-
 .../src/avcodec/avcodec_task_manager.cpp      |   7 +-
 .../src/avcodec/video_encoder.cpp             |  15 +-
 .../camera_service/src/hcapture_session.cpp   |   9 +-
 .../camera_service/src/hstream_capture.cpp    |  20 +-
 .../camera_service/src/hstream_common.cpp     |  11 +-
 .../camera_service/src/hstream_operator.cpp   | 132 ++++++++----
 .../avcodec_task_manager_fuzzer.cpp           |   3 +-
 .../capture_session_fuzzer.cpp                |   1 -
 .../hcapture_session_fuzzer.cpp               |   3 +-
 .../hstream_operator_fuzzer.cpp               |   5 +-
 30 files changed, 491 insertions(+), 263 deletions(-)

diff --git a/frameworks/js/camera_napi/src/output/photo_output_napi.cpp b/frameworks/js/camera_napi/src/output/photo_output_napi.cpp
index 3cbbd8228..0f7b30e79 100644
--- a/frameworks/js/camera_napi/src/output/photo_output_napi.cpp
+++ b/frameworks/js/camera_napi/src/output/photo_output_napi.cpp
@@ -62,6 +62,7 @@
 #include "metadata_helper.h"
 #include <drivers/interface/display/graphic/common/v1_0/cm_color_space.h>
 #include "picture_proxy.h"
+#include "hdr_type.h"
 
 namespace OHOS {
 namespace CameraStandard {
@@ -165,6 +166,28 @@ void ProcessCapture(PhotoOutputAsyncContext* context, bool isBurst)
     context->status = context->errorCode == 0;
 }
 
+void CopyMetaData(sptr<SurfaceBuffer> &inBuffer, sptr<SurfaceBuffer> &outBuffer)
+{
+    std::vector<uint32_t> keys = {};
+    CHECK_ERROR_RETURN_LOG(inBuffer == nullptr, "CopyMetaData: inBuffer is nullptr");
+    auto ret = inBuffer->ListMetadataKeys(keys);
+    CHECK_ERROR_RETURN_LOG(ret != GSError::GSERROR_OK,
+        "CopyMetaData: ListMetadataKeys fail! res=%{public}d", ret);
+    for (uint32_t key : keys) {
+        std::vector<uint8_t> values;
+        ret = inBuffer->GetMetadata(key, values);
+        if (ret != 0) {
+            MEDIA_INFO_LOG("GetMetadata fail! key = %{public}d res = %{public}d", key, ret);
+            continue;
+        }
+        ret = outBuffer->SetMetadata(key, values);
+        if (ret != 0) {
+            MEDIA_INFO_LOG("SetMetadata fail! key = %{public}d res = %{public}d", key, ret);
+            continue;
+        }
+    }
+}
+
 bool ValidQualityLevelFromJs(int32_t jsQuality)
 {
     MEDIA_INFO_LOG("PhotoOutputNapi::ValidQualityLevelFromJs quality level = %{public}d", jsQuality);
@@ -268,26 +291,6 @@ int32_t GetCaptureId(sptr<SurfaceBuffer> surfaceBuffer)
     return captureId;
 }
 
-OHOS::ColorManager::ColorSpace GetColorSpace(sptr<SurfaceBuffer> surfaceBuffer)
-{
-    OHOS::ColorManager::ColorSpace colorSpace =
-        OHOS::ColorManager::ColorSpace(OHOS::ColorManager::ColorSpaceName::NONE);
-    HDI::Display::Graphic::Common::V1_0::CM_ColorSpaceType colorSpaceType;
-    GSError gsErr = MetadataHelper::GetColorSpaceType(surfaceBuffer, colorSpaceType);
-    if (gsErr != GSERROR_OK) {
-        MEDIA_ERR_LOG("Failed to get colorSpaceType!");
-    } else {
-        MEDIA_INFO_LOG("get colorSpaceType:%{public}d", colorSpaceType);
-    }
-    auto it = COLORSPACE_MAP.find(colorSpaceType);
-    if (it != COLORSPACE_MAP.end()) {
-        colorSpace = it->second;
-    } else {
-        MEDIA_ERR_LOG("colorSpace not supported!");
-    }
-    return colorSpace;
-}
-
 void PictureListener::InitPictureListeners(napi_env env, wptr<PhotoOutput> photoOutput)
 {
     if (photoOutput == nullptr) {
@@ -1687,13 +1690,39 @@ void ThumbnailListener::OnBufferAvailable()
     MEDIA_INFO_LOG("ThumbnailListener::OnBufferAvailable is end");
 }
 
-void ThumbnailSetColorSpace(std::unique_ptr<Media::PixelMap>& pixelMap)
+OHOS::ColorManager::ColorSpaceName GetColorSpace(sptr<SurfaceBuffer> surfaceBuffer)
 {
+    OHOS::ColorManager::ColorSpaceName colorSpace = OHOS::ColorManager::ColorSpaceName::NONE;
+    HDI::Display::Graphic::Common::V1_0::CM_ColorSpaceType colorSpaceType;
+    GSError gsErr = MetadataHelper::GetColorSpaceType(surfaceBuffer, colorSpaceType);
+    if (gsErr != GSERROR_OK) {
+        MEDIA_ERR_LOG("Failed to get colorSpaceType from surfaceBuffer!");
+        return colorSpace;
+    } else {
+        MEDIA_INFO_LOG("Get current colorSpaceType is : %{public}d", colorSpaceType);
+    }
+    auto it = COLORSPACE_MAP.find(colorSpaceType);
+    if (it != COLORSPACE_MAP.end()) {
+        colorSpace = it->second;
+        MEDIA_INFO_LOG("Current get colorSpaceName: %{public}d", colorSpace);
+    } else {
+        MEDIA_ERR_LOG("Current colorSpace is not supported!");
+        return colorSpace;
+    }
+    return colorSpace;
+}
+
+void ThumbnailSetColorSpaceAndRotate(std::unique_ptr<Media::PixelMap>& pixelMap, sptr<SurfaceBuffer> surfaceBuffer,
+    OHOS::ColorManager::ColorSpaceName colorSpaceName)
+{
+    int32_t thumbnailrotation = 0;
+    surfaceBuffer->GetExtraData()->ExtraGet(OHOS::Camera::dataRotation, thumbnailrotation);
+    MEDIA_DEBUG_LOG("ThumbnailListener current rotation is : %{public}d", thumbnailrotation);
     if (!pixelMap) {
         MEDIA_ERR_LOG("ThumbnailListener Failed to create PixelMap.");
     } else {
-        OHOS::ColorManager::ColorSpace colorSpace(OHOS::ColorManager::ColorSpaceName::DISPLAY_P3);
-        pixelMap->InnerSetColorSpace(colorSpace);
+        pixelMap->InnerSetColorSpace(OHOS::ColorManager::ColorSpace(colorSpaceName));
+        pixelMap->rotate(thumbnailrotation);
     }
 }
 
@@ -1725,21 +1754,20 @@ void ThumbnailListener::ExecuteDeepCopySurfaceBuffer()
     int32_t captureId = GetCaptureId(surfaceBuffer);
     MEDIA_INFO_LOG("ThumbnailListener thumbnailWidth:%{public}d, thumbnailheight: %{public}d, captureId: %{public}d,"
         "burstSeqId: %{public}d", thumbnailWidth, thumbnailHeight, captureId, burstSeqId);
-    Media::InitializationOptions opts {
-        .size = { .width = thumbnailWidth, .height = thumbnailHeight },
-        .srcPixelFormat = Media::PixelFormat::RGBA_8888,
-        .pixelFormat = Media::PixelFormat::RGBA_8888,
-    };
-    const int32_t formatSize = 4;
-    auto pixelMap = Media::PixelMap::Create(static_cast<const uint32_t*>(surfaceBuffer->GetVirAddr()),
-        thumbnailWidth * thumbnailHeight * formatSize, 0, thumbnailWidth, opts, true);
-    ThumbnailSetColorSpace(pixelMap);
+    OHOS::ColorManager::ColorSpaceName colorSpace = GetColorSpace(surfaceBuffer);
+    CHECK_ERROR_RETURN_LOG(colorSpace == OHOS::ColorManager::ColorSpaceName::NONE, "Thumbnail GetcolorSpace failed!");
+    bool isHdr = colorSpace == OHOS::ColorManager::ColorSpaceName::BT2020_HLG;
+    sptr<SurfaceBuffer> newSurfaceBuffer = SurfaceBuffer::Create();
+    DeepCopyBuffer(newSurfaceBuffer, surfaceBuffer, thumbnailWidth, thumbnailHeight, isHdr);
+    std::unique_ptr<Media::PixelMap> pixelMap = CreatePixelMapFromSurfaceBuffer(newSurfaceBuffer,
+        thumbnailWidth, thumbnailHeight, isHdr);
+    CHECK_ERROR_RETURN_LOG(pixelMap == nullptr, "ThumbnailListener create pixelMap is nullptr");
+    ThumbnailSetColorSpaceAndRotate(pixelMap, surfaceBuffer, colorSpace);
     MEDIA_DEBUG_LOG("ThumbnailListener ReleaseBuffer begin");
     surface->ReleaseBuffer(surfaceBuffer, -1);
     MEDIA_DEBUG_LOG("ThumbnailListener ReleaseBuffer end");
     UpdateJSCallbackAsync(captureId, timestamp, std::move(pixelMap));
-    MEDIA_INFO_LOG("ThumbnailListener surfaceName = Thumbnail UpdateJSCallbackAsync captureId=%{public}d, end",
-        captureId);
+    MEDIA_INFO_LOG("ThumbnailListener surfaceName Thumbnail UpdateJSCallbackAsync captureId=%{public}d end", captureId);
     auto photoProxy = CreateCameraPhotoProxy(surfaceBuffer);
     if (photoOutput->IsYuvOrHeifPhoto()) {
         constexpr int32_t yuvFormat = 3;
@@ -1749,6 +1777,105 @@ void ThumbnailListener::ExecuteDeepCopySurfaceBuffer()
     }
 }
 
+void ThumbnailListener::DeepCopyBuffer(sptr<SurfaceBuffer> newSurfaceBuffer, sptr<SurfaceBuffer> surfaceBuffer,
+    int32_t thumbnailWidth, int32_t thumbnailHeight, bool isHdr) const
+{
+    CAMERA_SYNC_TRACE;
+    MEDIA_INFO_LOG("ThumbnailListener::DeepCopyBuffer w=%{public}d, h=%{public}d, f=%{public}d ",
+        thumbnailWidth, thumbnailHeight, surfaceBuffer->GetFormat());
+    int32_t thumbnailStride = 0;
+    surfaceBuffer->GetExtraData()->ExtraGet(OHOS::Camera::dataStride, thumbnailStride);
+    MEDIA_INFO_LOG("ThumbnailListener::DeepCopyBuffer current stride : %{public}d", thumbnailStride);
+    BufferRequestConfig requestConfig = {
+        .width = thumbnailStride,
+        .height = thumbnailHeight,
+        .strideAlignment = thumbnailStride,
+        .format = surfaceBuffer->GetFormat(),
+        .usage = BUFFER_USAGE_CPU_READ | BUFFER_USAGE_CPU_WRITE | BUFFER_USAGE_MEM_DMA | BUFFER_USAGE_MEM_MMZ_CACHE,
+        .timeout = 0,
+    };
+    CHECK_ERROR_RETURN_LOG(newSurfaceBuffer == nullptr, "Deep copy surfaceBuffer failed");
+    GSError allocErrorCode = newSurfaceBuffer->Alloc(requestConfig);
+    if (allocErrorCode != 0) {
+        MEDIA_ERR_LOG("Create surfaceBuffer Alloc failed");
+        return;
+    }
+    MEDIA_INFO_LOG("ThumbnailListener::DeepCopyBuffer SurfaceBuffer alloc ret : %{public}d",
+        allocErrorCode);
+    int32_t colorLength = thumbnailStride * thumbnailHeight * PIXEL_SIZE_HDR_YUV;
+    colorLength = isHdr ? colorLength : colorLength / HDR_PIXEL_SIZE;
+    if (memcpy_s(newSurfaceBuffer->GetVirAddr(), newSurfaceBuffer->GetSize(),
+        surfaceBuffer->GetVirAddr(), colorLength) != EOK) {
+        MEDIA_ERR_LOG("PhotoListener memcpy_s failed");
+        return;
+    }
+    CopyMetaData(surfaceBuffer, newSurfaceBuffer);
+    MEDIA_DEBUG_LOG("ThumbnailListener::DeepCopyBuffer SurfaceBuffer end");
+}
+
+unique_ptr<Media::PixelMap> ThumbnailListener::CreatePixelMapFromSurfaceBuffer(sptr<SurfaceBuffer> &surfaceBuffer,
+    int32_t width, int32_t height, bool isHdr)
+{
+    CHECK_ERROR_RETURN_RET_LOG(surfaceBuffer == nullptr, nullptr,
+        "ThumbnailListener::CreatePixelMapFromSurfaceBuffer surfaceBuffer is nullptr");
+    MEDIA_INFO_LOG("ThumbnailListener Width:%{public}d, height:%{public}d, isHdr:%{public}d, format:%{public}d",
+        width, height, isHdr, surfaceBuffer->GetFormat());
+    Media::InitializationOptions options {
+        .size = { .width = width, .height = height } };
+    options.srcPixelFormat = isHdr ? Media::PixelFormat::YCRCB_P010 : Media::PixelFormat::NV21;
+    options.pixelFormat = isHdr ? Media::PixelFormat::YCRCB_P010 : Media::PixelFormat::NV21;
+    options.useDMA = true;
+    int32_t colorLength = width * height * PIXEL_SIZE_HDR_YUV;
+    colorLength = isHdr ? colorLength : colorLength / HDR_PIXEL_SIZE;
+    std::unique_ptr<Media::PixelMap> pixelMap = Media::PixelMap::Create(options);
+    void* nativeBuffer = surfaceBuffer.GetRefPtr();
+    RefBase *ref = reinterpret_cast<RefBase *>(nativeBuffer);
+    ref->IncStrongRef(ref);
+    if (isHdr) {
+        pixelMap->SetHdrType(OHOS::Media::ImageHdrType::HDR_VIVID_SINGLE);
+    }
+    pixelMap->SetPixelsAddr(surfaceBuffer->GetVirAddr(), surfaceBuffer.GetRefPtr(), colorLength,
+        Media::AllocatorType::DMA_ALLOC, nullptr);
+    
+    MEDIA_DEBUG_LOG("ThumbnailListener::CreatePixelMapFromSurfaceBuffer end");
+    return SetPixelMapYuvInfo(surfaceBuffer, std::move(pixelMap), isHdr);
+}
+
+unique_ptr<Media::PixelMap> ThumbnailListener::SetPixelMapYuvInfo(sptr<SurfaceBuffer> &surfaceBuffer,
+    unique_ptr<Media::PixelMap> pixelMap, bool isHdr)
+{
+    MEDIA_INFO_LOG("ThumbnailListener::SetPixelMapYuvInf enter");
+    uint8_t ratio = isHdr ? HDR_PIXEL_SIZE : SDR_PIXEL_SIZE;
+    int32_t srcWidth = pixelMap->GetWidth();
+    int32_t srcHeight = pixelMap->GetHeight();
+    Media::YUVDataInfo yuvDataInfo = { .yWidth = srcWidth,
+                                       .yHeight = srcHeight,
+                                       .uvWidth = srcWidth / 2,
+                                       .uvHeight = srcHeight / 2,
+                                       .yStride = srcWidth,
+                                       .uvStride = srcWidth,
+                                       .uvOffset = srcWidth * srcHeight};
+    if (surfaceBuffer == nullptr) {
+        pixelMap->SetImageYUVInfo(yuvDataInfo);
+        return pixelMap;
+    }
+    OH_NativeBuffer_Planes *planes = nullptr;
+    GSError retVal = surfaceBuffer->GetPlanesInfo(reinterpret_cast<void**>(&planes));
+    if (retVal != OHOS::GSERROR_OK || planes == nullptr) {
+        pixelMap->SetImageYUVInfo(yuvDataInfo);
+        return pixelMap;
+    }
+    
+    yuvDataInfo.yStride = planes->planes[PLANE_Y].columnStride / ratio;
+    yuvDataInfo.uvStride = planes->planes[PLANE_U].columnStride / ratio;
+    yuvDataInfo.yOffset = planes->planes[PLANE_Y].offset / ratio;
+    yuvDataInfo.uvOffset = planes->planes[PLANE_U].offset / ratio;
+
+    pixelMap->SetImageYUVInfo(yuvDataInfo);
+    MEDIA_INFO_LOG("ThumbnailListener::SetPixelMapYuvInf end");
+    return pixelMap;
+}
+
 void ThumbnailListener::UpdateJSCallbackAsync(int32_t captureId, int64_t timestamp,
     unique_ptr<Media::PixelMap> pixelMap)
 {
diff --git a/frameworks/native/camera/src/session/capture_session.cpp b/frameworks/native/camera/src/session/capture_session.cpp
index cc399a5b7..43d1fda1e 100644
--- a/frameworks/native/camera/src/session/capture_session.cpp
+++ b/frameworks/native/camera/src/session/capture_session.cpp
@@ -321,8 +321,6 @@ int32_t CaptureSession::CommitConfig()
         auto preconfigProfiles = GetPreconfigProfiles();
         if (preconfigProfiles != nullptr) {
             SetColorSpace(preconfigProfiles->colorSpace);
-        } else {
-            SetDefaultColorSpace();
         }
     }
     // DELIVERY_PHOTO for default when commit
@@ -510,66 +508,6 @@ void CaptureSession::CreateCameraAbilityContainer()
     cameraAbilityContainer_ = new CameraAbilityContainer(abilities, conflictAbilities, this);
 }
 
-void CaptureSession::SetDefaultColorSpace()
-{
-    CM_ColorSpaceType metaColorSpace = CM_ColorSpaceType::CM_COLORSPACE_NONE;
-    CM_ColorSpaceType captureColorSpace = CM_ColorSpaceType::CM_COLORSPACE_NONE;
-    ColorSpaceInfo colorSpaceInfo = GetSupportedColorSpaceInfo();
-    if (colorSpaceInfo.modeCount == 0) {
-        MEDIA_ERR_LOG("CaptureSession::SetDefaultColorSpace SupportedColorSpaceInfo is null.");
-        return;
-    }
-    for (uint32_t i = 0; i < colorSpaceInfo.modeCount; i++) {
-        if (GetMode() != colorSpaceInfo.modeInfo[i].modeType) {
-            continue;
-        }
-        MEDIA_INFO_LOG("CaptureSession::SetDefaultColorSpace get %{public}d mode colorSpaceInfo success.", GetMode());
-        std::vector<int32_t> supportedColorSpaces = colorSpaceInfo.modeInfo[i].streamInfo[0].colorSpaces;
-        metaColorSpace = static_cast<CM_ColorSpaceType>(supportedColorSpaces[0]);
-        captureColorSpace = static_cast<CM_ColorSpaceType>(supportedColorSpaces[0]);
-        if (!IsModeWithVideoStream()) {
-            break;
-        }
-        for (uint32_t j = 0; j < colorSpaceInfo.modeInfo[i].streamTypeCount; j++) {
-            if (colorSpaceInfo.modeInfo[i].streamInfo[j].streamType == STILL_CAPTURE) {
-                captureColorSpace =
-                    static_cast<CM_ColorSpaceType>(colorSpaceInfo.modeInfo[i].streamInfo[j].colorSpaces[0]);
-                break;
-            }
-        }
-    }
-
-    auto captureSession = GetCaptureSession();
-    CHECK_ERROR_RETURN_LOG(!captureSession, "CaptureSession::SetDefaultColorSpace() captureSession is nullptr");
-
-    ColorSpace fwkColorSpace;
-    ColorSpace fwkCaptureColorSpace;
-    auto itr = g_metaColorSpaceMap_.find(metaColorSpace);
-    if (itr != g_metaColorSpaceMap_.end()) {
-        fwkColorSpace = itr->second;
-    } else {
-        MEDIA_ERR_LOG("CaptureSession::SetDefaultColorSpace, %{public}d failed", static_cast<int32_t>(metaColorSpace));
-        return;
-    }
-
-    itr = g_metaColorSpaceMap_.find(captureColorSpace);
-    if (itr != g_metaColorSpaceMap_.end()) {
-        fwkCaptureColorSpace = itr->second;
-    } else {
-        MEDIA_ERR_LOG("CaptureSession::SetDefaultColorSpace, %{public}d fail", static_cast<int32_t>(captureColorSpace));
-        return;
-    }
-    MEDIA_INFO_LOG("CaptureSession::SetDefaultColorSpace mode = %{public}d, ColorSpace = %{public}d, "
-        "captureColorSpace = %{public}d.", GetMode(), fwkColorSpace, fwkCaptureColorSpace);
-
-    int32_t errCode = captureSession->SetColorSpace(fwkColorSpace, fwkCaptureColorSpace, false);
-    if (errCode != CAMERA_OK) {
-        MEDIA_ERR_LOG("CaptureSession::SetDefaultColorSpace failed to SetColorSpace!, %{public}d",
-            ServiceToCameraError(errCode));
-    }
-    return;
-}
-
 bool CaptureSession::CanAddInput(sptr<CaptureInput>& input)
 {
     // can only add one cameraInput
@@ -3925,6 +3863,14 @@ ColorSpaceInfo CaptureSession::GetSupportedColorSpaceInfo()
     return colorSpaceInfo;
 }
 
+bool CheckColorSpaceForSystemApp(ColorSpace colorSpace)
+{
+    if (!CameraSecurity::CheckSystemApp() && colorSpace == ColorSpace::BT2020_HLG) {
+        return false;
+    }
+    return true;
+}
+
 std::vector<ColorSpace> CaptureSession::GetSupportedColorSpaces()
 {
     std::vector<ColorSpace> supportedColorSpaces = {};
@@ -3943,7 +3889,7 @@ std::vector<ColorSpace> CaptureSession::GetSupportedColorSpaces()
         supportedColorSpaces.reserve(colorSpaces.size());
         for (uint32_t j = 0; j < colorSpaces.size(); j++) {
             auto itr = g_metaColorSpaceMap_.find(static_cast<CM_ColorSpaceType>(colorSpaces[j]));
-            if (itr != g_metaColorSpaceMap_.end()) {
+            if (itr != g_metaColorSpaceMap_.end() && CheckColorSpaceForSystemApp(itr->second)) {
                 supportedColorSpaces.emplace_back(itr->second);
             }
         }
@@ -3981,86 +3927,35 @@ int32_t CaptureSession::SetColorSpace(ColorSpace colorSpace)
         MEDIA_ERR_LOG("CaptureSession::SetColorSpace Session is not Commited");
         return CameraErrorCode::SESSION_NOT_CONFIG;
     }
-
     auto captureSession = GetCaptureSession();
     CHECK_ERROR_RETURN_RET_LOG(!captureSession, CameraErrorCode::SERVICE_FATL_ERROR,
         "CaptureSession::SetColorSpace() captureSession is nullptr");
-    CM_ColorSpaceType metaColorSpace;
     auto itr = g_fwkColorSpaceMap_.find(colorSpace);
     CHECK_ERROR_RETURN_RET_LOG(itr == g_fwkColorSpaceMap_.end(), CameraErrorCode::INVALID_ARGUMENT,
         "CaptureSession::SetColorSpace() map failed, %{public}d", static_cast<int32_t>(colorSpace));
-    metaColorSpace = itr->second;
-    CM_ColorSpaceType captureColorSpace = metaColorSpace;
+    CM_ColorSpaceType fwkColorSpace = itr->second;
     ColorSpaceInfo colorSpaceInfo = GetSupportedColorSpaceInfo();
-
-    ColorSpace fwkCaptureColorSpace;
-    auto it = g_metaColorSpaceMap_.find(captureColorSpace);
-    CHECK_ERROR_RETURN_RET_LOG(it == g_metaColorSpaceMap_.end(), CameraErrorCode::INVALID_ARGUMENT,
-        "CaptureSession::SetColorSpace, %{public}d map failed", static_cast<int32_t>(captureColorSpace));
-    fwkCaptureColorSpace = it->second;
-    if (ProcessCaptureColorSpace(colorSpaceInfo, fwkCaptureColorSpace) != CameraErrorCode::SUCCESS) {
-        MEDIA_ERR_LOG("CaptureSession::SetDefaultColorSpace() is failed.");
-        return CameraErrorCode::INVALID_ARGUMENT;
-    }
-
-    if (IsSessionConfiged()) {
-        isColorSpaceSetted_ = true;
-    }
-    // 若session还未commit，则后续createStreams会把色域带下去；否则，SetColorSpace要走updateStreams
-    MEDIA_DEBUG_LOG("CaptureSession::SetColorSpace, IsSessionCommited %{public}d", IsSessionCommited());
-    int32_t errCode = captureSession->SetColorSpace(colorSpace, fwkCaptureColorSpace, IsSessionCommited());
-    CHECK_ERROR_PRINT_LOG(errCode != CAMERA_OK, "Failed to SetColorSpace!, %{public}d", errCode);
-    return ServiceToCameraError(errCode);
-}
-
-int32_t CaptureSession::ProcessCaptureColorSpace(ColorSpaceInfo colorSpaceInfo, ColorSpace& fwkCaptureColorSpace)
-{
-    CM_ColorSpaceType metaColorSpace;
-    CM_ColorSpaceType captureColorSpace;
     for (uint32_t i = 0; i < colorSpaceInfo.modeCount; i++) {
         if (GetMode() != colorSpaceInfo.modeInfo[i].modeType) {
             continue;
         }
-
-        auto it = g_fwkColorSpaceMap_.find(fwkCaptureColorSpace);
-        CHECK_ERROR_RETURN_RET_LOG(it == g_fwkColorSpaceMap_.end(), CameraErrorCode::INVALID_ARGUMENT,
-            "CaptureSession::SetColorSpace, %{public}d map failed", static_cast<int32_t>(fwkCaptureColorSpace));
-        metaColorSpace = it->second;
-        MEDIA_DEBUG_LOG("CaptureSession::SetColorSpace mode %{public}d, color %{public}d.", GetMode(), metaColorSpace);
         std::vector<int32_t> supportedColorSpaces = colorSpaceInfo.modeInfo[i].streamInfo[0].colorSpaces;
-        auto itColorSpace =
-            std::find(supportedColorSpaces.begin(), supportedColorSpaces.end(), static_cast<int32_t>(metaColorSpace));
-        if (itColorSpace == supportedColorSpaces.end()) {
-            MEDIA_ERR_LOG("CaptureSession::SetColorSpace input not found in supportedList.");
+        auto curColorSpace =
+            std::find(supportedColorSpaces.begin(), supportedColorSpaces.end(), static_cast<int32_t>(fwkColorSpace));
+        if (curColorSpace == supportedColorSpaces.end()) {
+            MEDIA_ERR_LOG("CaptureSession::SetColorSpace input colorSpace not found in supportedList.");
             return CameraErrorCode::INVALID_ARGUMENT;
         }
-
-        if (!IsModeWithVideoStream()) {
-            break;
-        }
-
-        captureColorSpace = metaColorSpace;
-        for (uint32_t j = 0; j < colorSpaceInfo.modeInfo[i].streamTypeCount; j++) {
-            if (colorSpaceInfo.modeInfo[i].streamInfo[j].streamType == OutputCapStreamType::STILL_CAPTURE) {
-                captureColorSpace =
-                    static_cast<CM_ColorSpaceType>(colorSpaceInfo.modeInfo[i].streamInfo[j].colorSpaces[0]);
-                MEDIA_DEBUG_LOG("CaptureSession::SetColorSpace captureColorSpace = %{public}d ", captureColorSpace);
-                break;
-            }
-        }
-        break;
+    }
+    if (IsSessionConfiged()) {
+        isColorSpaceSetted_ = true;
     }
 
-    auto it = g_metaColorSpaceMap_.find(captureColorSpace);
-    CHECK_ERROR_RETURN_RET_LOG(it == g_metaColorSpaceMap_.end(), CameraErrorCode::INVALID_ARGUMENT,
-        "CaptureSession::SetColorSpace, %{public}d map failed", static_cast<int32_t>(captureColorSpace));
-    fwkCaptureColorSpace = it->second;
-    return CameraErrorCode::SUCCESS;
-}
-
-bool CaptureSession::IsModeWithVideoStream()
-{
-    return GetMode() == SceneMode::VIDEO;
+    // 若session还未commit，则后续createStreams会把色域带下去；否则，SetColorSpace要走updateStreams
+    MEDIA_DEBUG_LOG("CaptureSession::SetColorSpace, IsSessionCommited %{public}d", IsSessionCommited());
+    int32_t errCode = captureSession->SetColorSpace(colorSpace, IsSessionCommited());
+    CHECK_ERROR_PRINT_LOG(errCode != CAMERA_OK, "Failed to SetColorSpace!, %{public}d", errCode);
+    return ServiceToCameraError(errCode);
 }
 
 std::vector<ColorEffect> CaptureSession::GetSupportedColorEffects()
diff --git a/frameworks/native/camera/test/moduletest/camera_session/src/camera_session_moduletest.cpp b/frameworks/native/camera/test/moduletest/camera_session/src/camera_session_moduletest.cpp
index 7e42320ea..fae19624f 100644
--- a/frameworks/native/camera/test/moduletest/camera_session/src/camera_session_moduletest.cpp
+++ b/frameworks/native/camera/test/moduletest/camera_session/src/camera_session_moduletest.cpp
@@ -7458,11 +7458,22 @@ HWTEST_F(CameraSessionModuleTest, photo_session_moduletest_024, TestSize.Level0)
     EXPECT_EQ(intResult, 0);
 
     std::vector<ColorSpace> colorSpaceLists = session_->GetSupportedColorSpaces();
+    bool falg = false;
+    for (auto curColorSpace : colorSpaceLists) {
+        if ( curColorSpace == ColorSpace::SRGB) {
+            falg = true;
+            break;
+        }
+    }
     if (colorSpaceLists.size() != 0) {
         ColorSpace colorSpace;
         intResult = session_->GetActiveColorSpace(colorSpace);
         EXPECT_EQ(intResult, 0);
-        EXPECT_EQ(colorSpaceLists[0], colorSpace);
+        if (!falg) {
+            MEDIA_ERR_LOG("current session not supported colorSpace SRGB");
+            return;
+        }
+        EXPECT_EQ(ColorSpace::SRGB, colorSpace);
     }
 
     intResult = session_->Start();
diff --git a/frameworks/native/camera/test/unittest/camera_service/avcodec/src/avcodec_task_manager_unittest.cpp b/frameworks/native/camera/test/unittest/camera_service/avcodec/src/avcodec_task_manager_unittest.cpp
index 938c0e79e..ede818f7b 100644
--- a/frameworks/native/camera/test/unittest/camera_service/avcodec/src/avcodec_task_manager_unittest.cpp
+++ b/frameworks/native/camera/test/unittest/camera_service/avcodec/src/avcodec_task_manager_unittest.cpp
@@ -64,7 +64,8 @@ HWTEST_F(AvcodecTaskManagerUnitTest, avcodec_task_manager_unittest_001, TestSize
 {
     sptr<AudioCapturerSession> session = new AudioCapturerSession();
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
-    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type);
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
+    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type, colorSpace);
 
     shared_ptr<TaskManager> manager = taskManager->GetTaskManager();
     ASSERT_NE(manager, nullptr);
@@ -95,7 +96,8 @@ HWTEST_F(AvcodecTaskManagerUnitTest, avcodec_task_manager_unittest_002, TestSize
 {
     sptr<AudioCapturerSession> session = new AudioCapturerSession();
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
-    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type);
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
+    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type, colorSpace);
 
     vector<sptr<FrameRecord>> frameRecords;
     uint64_t taskName = 1;
@@ -103,7 +105,7 @@ HWTEST_F(AvcodecTaskManagerUnitTest, avcodec_task_manager_unittest_002, TestSize
     int32_t captureId = 1;
     taskManager->DoMuxerVideo(frameRecords, taskName, captureRotation, captureId);
     EXPECT_TRUE(frameRecords.empty());
-    taskManager->videoEncoder_ = make_unique<VideoEncoder>(type);
+    taskManager->videoEncoder_ = make_unique<VideoEncoder>(type, colorSpace);
     taskManager->audioEncoder_ = nullptr;
 }
 
@@ -119,7 +121,8 @@ HWTEST_F(AvcodecTaskManagerUnitTest, avcodec_task_manager_unittest_003, TestSize
 {
     sptr<AudioCapturerSession> session = new AudioCapturerSession();
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
-    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type);
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
+    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type, colorSpace);
 
     vector<sptr<FrameRecord>> frameRecords;
     vector<sptr<FrameRecord>> choosedBuffer;
@@ -145,7 +148,8 @@ HWTEST_F(AvcodecTaskManagerUnitTest, avcodec_task_manager_unittest_004, TestSize
 {
     sptr<AudioCapturerSession> session = new AudioCapturerSession();
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
-    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type);
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
+    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type, colorSpace);
 
     taskManager->videoEncoder_ = nullptr;
     taskManager->audioEncoder_ = make_unique<AudioEncoder>();
@@ -165,9 +169,10 @@ HWTEST_F(AvcodecTaskManagerUnitTest, avcodec_task_manager_unittest_005, TestSize
 {
     sptr<AudioCapturerSession> session = new AudioCapturerSession();
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
-    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type);
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
+    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type, colorSpace);
 
-    taskManager->videoEncoder_ = make_unique<VideoEncoder>(type);
+    taskManager->videoEncoder_ = make_unique<VideoEncoder>(type, colorSpace);
     taskManager->audioEncoder_ = nullptr;
     taskManager->Stop();
     EXPECT_FALSE(taskManager->videoEncoder_->isStarted_);
diff --git a/frameworks/native/camera/test/unittest/camera_service/avcodec/src/moving_photo_video_cache_unittest.cpp b/frameworks/native/camera/test/unittest/camera_service/avcodec/src/moving_photo_video_cache_unittest.cpp
index c5d268938..d978586dc 100644
--- a/frameworks/native/camera/test/unittest/camera_service/avcodec/src/moving_photo_video_cache_unittest.cpp
+++ b/frameworks/native/camera/test/unittest/camera_service/avcodec/src/moving_photo_video_cache_unittest.cpp
@@ -70,10 +70,11 @@ HWTEST_F(MovingPhotoVideoCacheUnitTest, moving_photo_video_cache_unittest_001, T
 {
     sptr<AudioCapturerSession> session = new AudioCapturerSession();
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
-    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type);
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
+    sptr<AvcodecTaskManager> taskManager = new AvcodecTaskManager(session, type, colorSpace);
     sptr<MovingPhotoVideoCache> cache = new MovingPhotoVideoCache(taskManager);
 
-    sptr<AvcodecTaskManager> manager = new AvcodecTaskManager(session, type);
+    sptr<AvcodecTaskManager> manager = new AvcodecTaskManager(session, type, colorSpace);
     std::vector<sptr<FrameRecord>> frameRecords;
     uint64_t taskName = 1;
     int32_t rotation = 1;
@@ -118,7 +119,8 @@ HWTEST_F(MovingPhotoVideoCacheUnitTest, moving_photo_video_cache_unittest_003, T
 {
     sptr<AudioCapturerSession> session = new AudioCapturerSession();
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
-    sptr<AvcodecTaskManager> manager = new AvcodecTaskManager(session, type);
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
+    sptr<AvcodecTaskManager> manager = new AvcodecTaskManager(session, type, colorSpace);
     std::vector<sptr<FrameRecord>> frameRecords;
     uint64_t taskName = 1;
     int32_t rotation = 1;
@@ -153,7 +155,8 @@ HWTEST_F(MovingPhotoVideoCacheUnitTest, moving_photo_video_cache_unittest_004, T
 {
     sptr<AudioCapturerSession> session = new AudioCapturerSession();
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
-    sptr<AvcodecTaskManager> manager = new AvcodecTaskManager(session, type);
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
+    sptr<AvcodecTaskManager> manager = new AvcodecTaskManager(session, type, colorSpace);
     std::vector<sptr<FrameRecord>> frameRecords;
     uint64_t taskName = 1;
     int32_t rotation = 1;
diff --git a/frameworks/native/camera/test/unittest/camera_service/avcodec/src/video_encoder_unittest.cpp b/frameworks/native/camera/test/unittest/camera_service/avcodec/src/video_encoder_unittest.cpp
index 91c6c88fa..82b454967 100644
--- a/frameworks/native/camera/test/unittest/camera_service/avcodec/src/video_encoder_unittest.cpp
+++ b/frameworks/native/camera/test/unittest/camera_service/avcodec/src/video_encoder_unittest.cpp
@@ -63,7 +63,8 @@ void VideoEncoderUnitTest::TearDown()
 HWTEST_F(VideoEncoderUnitTest, video_encoder_unittest_001, TestSize.Level0)
 {
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
-    std::shared_ptr<VideoEncoder> encoder = make_unique<VideoEncoder>(type);
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
+    std::shared_ptr<VideoEncoder> encoder = make_unique<VideoEncoder>(type, colorSpace);
     int32_t rotation = 1;
     std::shared_ptr<Size> size = std::make_shared<Size>();
     encoder->RestartVideoCodec(size, rotation);
@@ -90,7 +91,8 @@ HWTEST_F(VideoEncoderUnitTest, video_encoder_unittest_001, TestSize.Level0)
 HWTEST_F(VideoEncoderUnitTest, video_encoder_unittest_002, TestSize.Level0)
 {
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
-    std::shared_ptr<VideoEncoder> encoder = make_unique<VideoEncoder>(type);
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
+    std::shared_ptr<VideoEncoder> encoder = make_unique<VideoEncoder>(type, colorSpace);
 
     sptr<SurfaceBuffer> videoBuffer = SurfaceBuffer::Create();
     ASSERT_NE(videoBuffer, nullptr);
@@ -129,7 +131,8 @@ HWTEST_F(VideoEncoderUnitTest, video_encoder_unittest_002, TestSize.Level0)
 HWTEST_F(VideoEncoderUnitTest, video_encoder_unittest_003, TestSize.Level0)
 {
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
-    std::shared_ptr<VideoEncoder> encoder = make_unique<VideoEncoder>(type);
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
+    std::shared_ptr<VideoEncoder> encoder = make_unique<VideoEncoder>(type, colorSpace);
     encoder->encoder_ = nullptr;
     EXPECT_EQ(encoder->Release(), 0);
 }
diff --git a/frameworks/native/camera/test/unittest/camera_service/hdi_camera_test/src/hcamera_service_unittest.cpp b/frameworks/native/camera/test/unittest/camera_service/hdi_camera_test/src/hcamera_service_unittest.cpp
index bb008f408..53a9fd3a5 100644
--- a/frameworks/native/camera/test/unittest/camera_service/hdi_camera_test/src/hcamera_service_unittest.cpp
+++ b/frameworks/native/camera/test/unittest/camera_service/hdi_camera_test/src/hcamera_service_unittest.cpp
@@ -1366,8 +1366,7 @@ HWTEST_F(HCameraServiceUnit, HCamera_service_unittest_035, TestSize.Level0)
  * EnvConditions: NA
  * CaseDescription: Test RegisterSensorCallback and UnregisterSensorCallback in a various order
  */
-HWTEST_F(HCameraServiceUnit, HCamera_service_unittest_036, TestSize.Level0)
-{
+HWTEST_F(HCameraServiceUnit, HCamera_service_unittest_036, TestSize.Level0) {
     std::vector<string> cameraIds;
     cameraService_->GetCameraIds(cameraIds);
     ASSERT_NE(cameraIds.size(), 0);
diff --git a/frameworks/native/camera/test/unittest/camera_service/hdi_stream_test/src/hcapture_session_unittest.cpp b/frameworks/native/camera/test/unittest/camera_service/hdi_stream_test/src/hcapture_session_unittest.cpp
index 4ae0e5464..98675498b 100644
--- a/frameworks/native/camera/test/unittest/camera_service/hdi_stream_test/src/hcapture_session_unittest.cpp
+++ b/frameworks/native/camera/test/unittest/camera_service/hdi_stream_test/src/hcapture_session_unittest.cpp
@@ -419,8 +419,7 @@ HWTEST_F(HCaptureSessionUnitTest, hcapture_session_unit_test_006, TestSize.Level
     EXPECT_EQ(session->AddOutput(StreamType::REPEAT, streamRepeat), CAMERA_OK);
     session->CommitConfig();
 
-    EXPECT_EQ(session->SetColorSpace(ColorSpace::BT2020_HLG,
-        ColorSpace::BT2020_HLG, true), CAMERA_OPERATION_NOT_ALLOWED);
+    EXPECT_EQ(session->SetColorSpace(ColorSpace::BT2020_HLG, true), CAMERA_OPERATION_NOT_ALLOWED);
 
     EXPECT_EQ(device->Close(), CAMERA_OK);
     EXPECT_EQ(session->Release(), CAMERA_OK);
@@ -1792,10 +1791,8 @@ HWTEST_F(HCaptureSessionUnitTest, hcapture_session_unit_test_035, TestSize.Level
 
     bool isNeedUpdate = false;
     ColorSpace colorSpace = ColorSpace::SRGB;
-    ColorSpace captureColorSpace = ColorSpace::SRGB;
-    EXPECT_EQ(camSession->SetColorSpace(colorSpace, captureColorSpace, isNeedUpdate), CAMERA_INVALID_STATE);
-    captureColorSpace = ColorSpace::SRGB;
-    EXPECT_EQ(camSession->SetColorSpace(colorSpace, captureColorSpace, isNeedUpdate), CAMERA_INVALID_STATE);
+    EXPECT_EQ(camSession->SetColorSpace(colorSpace, isNeedUpdate), CAMERA_INVALID_STATE);
+    EXPECT_EQ(camSession->SetColorSpace(colorSpace, isNeedUpdate), CAMERA_INVALID_STATE);
     camSession->Release();
 }
 
diff --git a/frameworks/native/camera/test/unittest/framework_native/session/src/capture_session_unittest.cpp b/frameworks/native/camera/test/unittest/framework_native/session/src/capture_session_unittest.cpp
index a323c8eb9..c4106d87b 100644
--- a/frameworks/native/camera/test/unittest/framework_native/session/src/capture_session_unittest.cpp
+++ b/frameworks/native/camera/test/unittest/framework_native/session/src/capture_session_unittest.cpp
@@ -3840,6 +3840,101 @@ HWTEST_F(CaptureSessionUnitTest, capture_session_unittest_041, TestSize.Level0)
     session->Release();
 }
 
+/*
+ * Feature: Framework
+ * Function: Test CaptureSession with SetColorSpace HDR and GetActiveColorSpace when Configed.
+ * SubFunction: NA
+ * FunctionPoints: NA
+ * EnvConditions: NA
+ * CaseDescription: Test CaptureSession with SetColorSpace and GetActiveColorSpace when Configed.
+ */
+HWTEST_F(CaptureSessionUnitTest, capture_session_unit_043, TestSize.Level0)
+{
+    sptr<CaptureInput> input = cameraManager_->CreateCameraInput(cameras_[0]);
+    sptr<Surface> surface = Surface::CreateSurfaceAsConsumer();
+    ASSERT_NE(input, nullptr);
+
+    sptr<CameraInput> camInput = (sptr<CameraInput> &)input;
+    std::string cameraSettings = camInput->GetCameraSettings();
+    camInput->SetCameraSettings(cameraSettings);
+    camInput->GetCameraDevice()->Open();
+
+    sptr<CaptureSession> session = cameraManager_->CreateCaptureSession();
+    ASSERT_NE(session, nullptr);
+    UpdataCameraOutputCapability();
+    sptr<CaptureOutput> preview = nullptr;
+    for (const auto& preProfile : previewProfile_) {
+        if (preProfile.format_ == CAMERA_FORMAT_YCRCB_P010) {
+            preview = CreatePreviewOutput(preProfile);
+            break;
+        }
+    }
+
+    if (preview == nullptr) {
+        MEDIA_WARNING_LOG("Format YCRCB_P010 is not supported!");
+        return;
+    }
+    
+    ColorSpace colorSpace = BT2020_HLG;
+    EXPECT_EQ(session->BeginConfig(), 0);
+    EXPECT_EQ(session->SetColorSpace(colorSpace), 0);
+    EXPECT_EQ(session->GetActiveColorSpace(colorSpace), 0);
+    EXPECT_EQ(session->AddInput(input), 0);
+    EXPECT_EQ(session->AddOutput(preview), 0);
+
+    EXPECT_EQ(session->CommitConfig(), 0);
+
+    session->LockForControl();
+    session->UnlockForControl();
+
+    EXPECT_EQ(preview->Release(), 0);
+    EXPECT_EQ(input->Release(), 0);
+    EXPECT_EQ(session->Release(), 0);
+}
+
+/*
+ * Feature: Framework
+ * Function: Test CaptureSession with SetColorSpace HDR and GetActiveColorSpace when not Configed.
+ * SubFunction: NA
+ * FunctionPoints: NA
+ * EnvConditions: NA
+ * CaseDescription: Test CaptureSession with SetColorSpace and GetActiveColorSpace when not Configed.
+ */
+HWTEST_F(CaptureSessionUnitTest, capture_session_unit_044, TestSize.Level0)
+{
+    sptr<CaptureInput> input = cameraManager_->CreateCameraInput(cameras_[0]);
+    sptr<Surface> surface = Surface::CreateSurfaceAsConsumer();
+    ASSERT_NE(input, nullptr);
+
+    sptr<CameraInput> camInput = (sptr<CameraInput> &)input;
+    std::string cameraSettings = camInput->GetCameraSettings();
+    camInput->SetCameraSettings(cameraSettings);
+    camInput->GetCameraDevice()->Open();
+
+    sptr<CaptureSession> session = cameraManager_->CreateCaptureSession();
+    ASSERT_NE(session, nullptr);
+    UpdataCameraOutputCapability();
+    sptr<CaptureOutput> preview = nullptr;
+    for (const auto& preProfile : previewProfile_) {
+        if (preProfile.format_ == CAMERA_FORMAT_YCRCB_P010) {
+            preview = CreatePreviewOutput(preProfile);
+            break;
+        }
+    }
+    if (preview == nullptr) {
+        MEDIA_WARNING_LOG("Format YCRCB_P010 is not supported!");
+        return;
+    }
+
+    ColorSpace colorSpace = BT2020_HLG;
+    EXPECT_EQ(session->SetColorSpace(colorSpace), CameraErrorCode::SESSION_NOT_CONFIG);
+    EXPECT_EQ(session->GetActiveColorSpace(colorSpace), CameraErrorCode::SESSION_NOT_CONFIG);
+
+    EXPECT_EQ(preview->Release(), 0);
+    EXPECT_EQ(input->Release(), 0);
+    EXPECT_EQ(session->Release(), 0);
+}
+
 /*
  * Feature: Framework
  * Function: Test FoldCallback with OnFoldStatusChanged
diff --git a/interfaces/inner_api/native/camera/include/session/capture_session.h b/interfaces/inner_api/native/camera/include/session/capture_session.h
index c7f579469..c5906ddbf 100644
--- a/interfaces/inner_api/native/camera/include/session/capture_session.h
+++ b/interfaces/inner_api/native/camera/include/session/capture_session.h
@@ -2191,11 +2191,8 @@ private:
     void OnSettingUpdated(std::shared_ptr<OHOS::Camera::CameraMetadata> changedMetadata);
     void OnResultReceived(std::shared_ptr<OHOS::Camera::CameraMetadata> changedMetadata);
     ColorSpaceInfo GetSupportedColorSpaceInfo();
-    bool IsModeWithVideoStream();
-    void SetDefaultColorSpace();
     void UpdateDeviceDeferredability();
     void ProcessProfilesAbilityId(const SceneMode supportModes);
-    int32_t ProcessCaptureColorSpace(ColorSpaceInfo colorSpaceInfo, ColorSpace& fwkCaptureColorSpace);
     void ProcessFocusDistanceUpdates(const std::shared_ptr<OHOS::Camera::CameraMetadata>& result);
     void FindTagId();
     bool CheckFrameRateRangeWithCurrentFps(int32_t curMinFps, int32_t curMaxFps, int32_t minFps, int32_t maxFps);
diff --git a/interfaces/kits/js/camera_napi/include/output/photo_output_napi.h b/interfaces/kits/js/camera_napi/include/output/photo_output_napi.h
index f843365e2..d1bcbc062 100644
--- a/interfaces/kits/js/camera_napi/include/output/photo_output_napi.h
+++ b/interfaces/kits/js/camera_napi/include/output/photo_output_napi.h
@@ -27,6 +27,7 @@
 #include "native_image.h"
 #include "output/camera_output_capability.h"
 #include "output/photo_output.h"
+#include "pixel_map.h"
 
 namespace OHOS::Media {
     class PixelMap;
@@ -258,6 +259,19 @@ private:
     void UpdateJSCallback(int32_t captureId, int64_t timestamp, unique_ptr<Media::PixelMap>) const;
     void UpdateJSCallbackAsync(int32_t captureId, int64_t timestamp, unique_ptr<Media::PixelMap>);
     void ExecuteDeepCopySurfaceBuffer();
+    
+    unique_ptr<Media::PixelMap> CreatePixelMapFromSurfaceBuffer(sptr<SurfaceBuffer> &surfaceBuffer,
+        int32_t width, int32_t height, bool isHdr);
+    unique_ptr<Media::PixelMap> SetPixelMapYuvInfo(sptr<SurfaceBuffer> &surfaceBuffer,
+        unique_ptr<Media::PixelMap> pixelMap, bool isHdr);
+    void DeepCopyBuffer(sptr<SurfaceBuffer> newSurfaceBuffer, sptr<SurfaceBuffer> surfaceBuffer,
+        int32_t thumbnailWidth, int32_t thumbnailHeight, bool isHdr) const;
+
+    static constexpr int32_t PLANE_Y = 0;
+    static constexpr int32_t PLANE_U = 1;
+    static constexpr uint8_t PIXEL_SIZE_HDR_YUV = 3;
+    static constexpr uint8_t  HDR_PIXEL_SIZE = 2;
+    static constexpr uint8_t SDR_PIXEL_SIZE = 1;
 };
 
 struct ThumbnailListenerInfo {
diff --git a/services/camera_service/binder/base/include/icapture_session.h b/services/camera_service/binder/base/include/icapture_session.h
index b7188abae..8ee8d85e7 100644
--- a/services/camera_service/binder/base/include/icapture_session.h
+++ b/services/camera_service/binder/base/include/icapture_session.h
@@ -69,7 +69,7 @@ public:
 
     virtual int32_t GetActiveColorSpace(ColorSpace& colorSpace) = 0;
 
-    virtual int32_t SetColorSpace(ColorSpace colorSpace, ColorSpace captureColorSpace, bool isNeedUpdate) = 0;
+    virtual int32_t SetColorSpace(ColorSpace colorSpace, bool isNeedUpdate) = 0;
 
     virtual int32_t SetFeatureMode(int32_t featureMode) = 0;
 
diff --git a/services/camera_service/binder/client/include/hcapture_session_proxy.h b/services/camera_service/binder/client/include/hcapture_session_proxy.h
index c76f5d6ae..222ae7b2c 100644
--- a/services/camera_service/binder/client/include/hcapture_session_proxy.h
+++ b/services/camera_service/binder/client/include/hcapture_session_proxy.h
@@ -59,7 +59,7 @@ public:
 
     int32_t GetActiveColorSpace(ColorSpace& colorSpace) override;
 
-    int32_t SetColorSpace(ColorSpace colorSpace, ColorSpace captureColorSpace, bool isNeedUpdate) override;
+    int32_t SetColorSpace(ColorSpace colorSpace, bool isNeedUpdate) override;
 
     int32_t SetFeatureMode(int32_t featureMode) override;
 
diff --git a/services/camera_service/binder/client/src/hcapture_session_proxy.cpp b/services/camera_service/binder/client/src/hcapture_session_proxy.cpp
index 2e78ab247..5590a8d6f 100644
--- a/services/camera_service/binder/client/src/hcapture_session_proxy.cpp
+++ b/services/camera_service/binder/client/src/hcapture_session_proxy.cpp
@@ -289,7 +289,7 @@ int32_t HCaptureSessionProxy::GetActiveColorSpace(ColorSpace& colorSpace)
     return error;
 }
 
-int32_t HCaptureSessionProxy::SetColorSpace(ColorSpace colorSpace, ColorSpace captureColorSpace, bool isNeedUpdate)
+int32_t HCaptureSessionProxy::SetColorSpace(ColorSpace colorSpace, bool isNeedUpdate)
 {
     MessageParcel data;
     MessageParcel reply;
@@ -297,7 +297,6 @@ int32_t HCaptureSessionProxy::SetColorSpace(ColorSpace colorSpace, ColorSpace ca
 
     data.WriteInterfaceToken(GetDescriptor());
     data.WriteInt32(static_cast<int32_t>(colorSpace));
-    data.WriteInt32(static_cast<int32_t>(captureColorSpace));
     data.WriteBool(isNeedUpdate);
 
     int error = Remote()->SendRequest(
diff --git a/services/camera_service/binder/server/src/hcapture_session_stub.cpp b/services/camera_service/binder/server/src/hcapture_session_stub.cpp
index 85b55bfec..b572245ad 100644
--- a/services/camera_service/binder/server/src/hcapture_session_stub.cpp
+++ b/services/camera_service/binder/server/src/hcapture_session_stub.cpp
@@ -229,9 +229,8 @@ int HCaptureSessionStub::HandleGetActiveColorSpace(MessageParcel &reply)
 int HCaptureSessionStub::HandleSetColorSpace(MessageParcel &data)
 {
     ColorSpace colorSpace = static_cast<ColorSpace>(data.ReadInt32());
-    ColorSpace colorSpaceForCapture = static_cast<ColorSpace>(data.ReadInt32());
     bool isNeedUpdate = data.ReadBool();
-    return SetColorSpace(colorSpace, colorSpaceForCapture, isNeedUpdate);
+    return SetColorSpace(colorSpace, isNeedUpdate);
 }
 
 int HCaptureSessionStub::HandleSetSmoothZoom(MessageParcel &data, MessageParcel &reply)
diff --git a/services/camera_service/include/avcodec/avcodec_task_manager.h b/services/camera_service/include/avcodec/avcodec_task_manager.h
index 9e277d7c4..738a217b8 100644
--- a/services/camera_service/include/avcodec/avcodec_task_manager.h
+++ b/services/camera_service/include/avcodec/avcodec_task_manager.h
@@ -51,7 +51,8 @@ constexpr uint32_t RELEASE_WAIT_TIME = 10000;
 
 class AvcodecTaskManager : public RefBase, public std::enable_shared_from_this<AvcodecTaskManager> {
 public:
-    explicit AvcodecTaskManager(sptr<AudioCapturerSession> audioCapturerSession, VideoCodecType type);
+    explicit AvcodecTaskManager(sptr<AudioCapturerSession> audioCapturerSession, VideoCodecType type,
+        ColorSpace colorSpace);
     ~AvcodecTaskManager();
     void EncodeVideoBuffer(sptr<FrameRecord> frameRecord, CacheCbFunc cacheCallback);
     void PrepareAudioBuffer(vector<sptr<FrameRecord>>& choosedBuffer, vector<sptr<AudioRecord>>& audioRecords,
@@ -97,6 +98,7 @@ private:
     int64_t postBufferDuration_ = NANOSEC_RANGE;
     uint32_t timerId_ = 0;
     shared_ptr<AudioDeferredProcess> audioDeferredProcess_ = nullptr;
+    ColorSpace colorSpace_ = ColorSpace::COLOR_SPACE_UNKNOWN;
 };
 } // CameraStandard
 } // OHOS
diff --git a/services/camera_service/include/avcodec/common/sample_info.h b/services/camera_service/include/avcodec/common/sample_info.h
index fa1d2ac92..eafc40943 100644
--- a/services/camera_service/include/avcodec/common/sample_info.h
+++ b/services/camera_service/include/avcodec/common/sample_info.h
@@ -66,6 +66,7 @@ constexpr float VIDEO_BITRATE_CONSTANT = 0.7;
 constexpr float HEVC_TO_AVC_FACTOR = 1.5;
 constexpr int64_t NANOSEC_RANGE = 1600000000LL;
 constexpr int32_t I32_TWO = 2;
+constexpr bool IS_HDR_VIVID = true;
 
 class CodecAVBufferInfo : public RefBase {
 public:
diff --git a/services/camera_service/include/avcodec/video_encoder.h b/services/camera_service/include/avcodec/video_encoder.h
index d67c5295d..2e9ed86ad 100644
--- a/services/camera_service/include/avcodec/video_encoder.h
+++ b/services/camera_service/include/avcodec/video_encoder.h
@@ -22,6 +22,7 @@
 #include "sample_info.h"
 #include "camera_util.h"
 #include "surface_buffer.h"
+#include "icapture_session.h"
 
 namespace OHOS {
 namespace CameraStandard {
@@ -30,7 +31,7 @@ using namespace OHOS::MediaAVCodec;
 class VideoEncoder : public std::enable_shared_from_this<VideoEncoder> {
 public:
     VideoEncoder() = default;
-    explicit VideoEncoder(VideoCodecType type);
+    explicit VideoEncoder(VideoCodecType type, ColorSpace colorSpace);
     ~VideoEncoder();
 
     int32_t Create(const std::string &codecMime);
@@ -55,6 +56,7 @@ public:
     private:
         std::weak_ptr<VideoEncoder> videoEncoder_;
     };
+    bool IsHdr(ColorSpace colorSpace);
 
 private:
     int32_t SetCallback();
@@ -75,6 +77,7 @@ private:
     int32_t bitrate_ = 0;
     bool successFrame_ = false;
     int64_t preFrameTimestamp_ = 0;
+    bool isHdr_ = false;
 };
 } // CameraStandard
 } // OHOS
diff --git a/services/camera_service/include/hcapture_session.h b/services/camera_service/include/hcapture_session.h
index a98a2479e..acc641f59 100644
--- a/services/camera_service/include/hcapture_session.h
+++ b/services/camera_service/include/hcapture_session.h
@@ -118,7 +118,7 @@ public:
 
     int32_t GetSessionState(CaptureSessionState& sessionState) override;
     int32_t GetActiveColorSpace(ColorSpace& colorSpace) override;
-    int32_t SetColorSpace(ColorSpace colorSpace, ColorSpace captureColorSpace, bool isNeedUpdate) override;
+    int32_t SetColorSpace(ColorSpace colorSpace, bool isNeedUpdate) override;
     bool QueryFpsAndZoomRatio(float& currentFps, float& currentZoomRatio);
     bool QueryZoomPerformance(std::vector<float>& crossZoomAndTime, int32_t operationMode);
     int32_t GetRangeId(float& zoomRatio, std::vector<float>& crossZoom);
@@ -165,6 +165,7 @@ public:
     void BeforeDeviceClose() override;
 
 private:
+    void InitDefaultColortSpace(SceneMode opMode);
     explicit HCaptureSession(const uint32_t callingTokenId, int32_t opMode);
     string lastDisplayName_ = "";
     string lastBurstPrefix_ = "";
diff --git a/services/camera_service/include/hstream_operator.h b/services/camera_service/include/hstream_operator.h
index 074199fe0..1056a0e8f 100644
--- a/services/camera_service/include/hstream_operator.h
+++ b/services/camera_service/include/hstream_operator.h
@@ -183,9 +183,10 @@ public:
     void ReleaseStreams();
     void StopMovingPhoto();
     int32_t GetActiveColorSpace(ColorSpace& colorSpace);
-    int32_t SetColorSpace(ColorSpace colorSpace, ColorSpace captureColorSpace, bool isNeedUpdate);
+    int32_t SetColorSpace(ColorSpace colorSpace, bool isNeedUpdate);
     void SetColorSpaceForStreams();
     int32_t CheckIfColorSpaceMatchesFormat(ColorSpace colorSpace);
+    bool CheckFormat(ColorSpace colorSpace, camera_format_t format, StreamType streamType);
     int32_t StartPreviewStream(const std::shared_ptr<OHOS::Camera::CameraMetadata>& settings,
         camera_position_enum_t cameraPosition);
 
@@ -283,6 +284,7 @@ private:
 
     std::shared_ptr<PhotoAssetIntf> ProcessPhotoProxy(int32_t captureId, std::shared_ptr<PictureIntf> picturePtr,
         bool isBursting, sptr<CameraServerPhotoProxy> cameraPhotoProxy, std::string& uri);
+    void InitDefaultColortSpace(SceneMode opMode);
 
 #ifdef CAMERA_USE_SENSOR
     std::mutex sensorLock_;
@@ -307,7 +309,6 @@ private:
     uint32_t callerToken_;
     int32_t opMode_;
     ColorSpace currColorSpace_ = ColorSpace::COLOR_SPACE_UNKNOWN;
-    ColorSpace currCaptureColorSpace_ = ColorSpace::COLOR_SPACE_UNKNOWN;
     bool isSessionStarted_ = false;
     bool enableStreamRotate_ = false;
     bool isDynamicConfiged_ = false;
diff --git a/services/camera_service/src/avcodec/avcodec_task_manager.cpp b/services/camera_service/src/avcodec/avcodec_task_manager.cpp
index e178b8d52..319982658 100644
--- a/services/camera_service/src/avcodec/avcodec_task_manager.cpp
+++ b/services/camera_service/src/avcodec/avcodec_task_manager.cpp
@@ -53,7 +53,7 @@ AvcodecTaskManager::~AvcodecTaskManager()
 }
 
 AvcodecTaskManager::AvcodecTaskManager(sptr<AudioCapturerSession> audioCaptureSession,
-    VideoCodecType type) : videoCodecType_(type)
+    VideoCodecType type, ColorSpace colorSpace) : videoCodecType_(type), colorSpace_(colorSpace)
 {
     CAMERA_SYNC_TRACE;
     #ifdef MOVING_PHOTO_ADD_AUDIO
@@ -61,7 +61,7 @@ AvcodecTaskManager::AvcodecTaskManager(sptr<AudioCapturerSession> audioCaptureSe
     audioEncoder_ = make_unique<AudioEncoder>();
     #endif
     // Create Task Manager
-    videoEncoder_ = make_shared<VideoEncoder>(type);
+    videoEncoder_ = make_shared<VideoEncoder>(type, colorSpace);
 }
 
 shared_ptr<TaskManager>& AvcodecTaskManager::GetTaskManager()
@@ -161,6 +161,9 @@ sptr<AudioVideoMuxer> AvcodecTaskManager::CreateAVMuxer(vector<sptr<FrameRecord>
     MEDIA_INFO_LOG("CreateAVMuxer videoCodecType_ = %{public}d", videoCodecType_);
     formatVideo->PutStringValue(MediaDescriptionKey::MD_KEY_CODEC_MIME, videoCodecType_
         == VIDEO_ENCODE_TYPE_HEVC ? OH_AVCODEC_MIMETYPE_VIDEO_HEVC : OH_AVCODEC_MIMETYPE_VIDEO_AVC);
+    if (videoCodecType_ == VIDEO_ENCODE_TYPE_HEVC && videoEncoder_->IsHdr(colorSpace_)) {
+        formatVideo->PutIntValue(MediaDescriptionKey::MD_KEY_VIDEO_IS_HDR_VIVID, IS_HDR_VIVID);
+    }
     formatVideo->PutIntValue(MediaDescriptionKey::MD_KEY_WIDTH, frameRecords[0]->GetFrameSize()->width);
     formatVideo->PutIntValue(MediaDescriptionKey::MD_KEY_HEIGHT, frameRecords[0]->GetFrameSize()->height);
     formatVideo->PutDoubleValue(MediaDescriptionKey::MD_KEY_FRAME_RATE, VIDEO_FRAME_RATE);
diff --git a/services/camera_service/src/avcodec/video_encoder.cpp b/services/camera_service/src/avcodec/video_encoder.cpp
index 237bff935..7a2a14966 100644
--- a/services/camera_service/src/avcodec/video_encoder.cpp
+++ b/services/camera_service/src/avcodec/video_encoder.cpp
@@ -30,13 +30,21 @@ VideoEncoder::~VideoEncoder()
     }
     Release();
 }
-
-VideoEncoder::VideoEncoder(VideoCodecType type) : videoCodecType_(type)
+VideoEncoder::VideoEncoder(VideoCodecType type, ColorSpace colorSpace) : videoCodecType_(type),
+    isHdr_(IsHdr(colorSpace))
 {
     rotation_ = 0;
     MEDIA_INFO_LOG("VideoEncoder enter");
 }
 
+bool VideoEncoder::IsHdr(ColorSpace colorSpace)
+{
+    std::vector<ColorSpace> hdrColorSpaces = {BT2020_HLG, BT2020_PQ, BT2020_HLG_LIMIT,
+                                             BT2020_PQ_LIMIT};
+    auto it = std::find(hdrColorSpaces.begin(), hdrColorSpaces.end(), colorSpace);
+    return it != hdrColorSpaces.end();
+}
+
 int32_t VideoEncoder::Create(const std::string &codecMime)
 {
     std::lock_guard<std::mutex> lock(encoderMutex_);
@@ -356,6 +364,9 @@ int32_t VideoEncoder::Configure()
     format.PutLongValue(MediaDescriptionKey::MD_KEY_BITRATE, bitrate_);
     format.PutIntValue(MediaDescriptionKey::MD_KEY_PIXEL_FORMAT, VIDOE_PIXEL_FORMAT);
     format.PutIntValue(MediaDescriptionKey::MD_KEY_I_FRAME_INTERVAL, INT_MAX);
+    if (videoCodecType_ == VideoCodecType::VIDEO_ENCODE_TYPE_HEVC && isHdr_) {
+        format.PutIntValue(MediaDescriptionKey::MD_KEY_PROFILE, HEVC_PROFILE_MAIN_10);
+    }
     int ret = encoder_->Configure(format);
     CHECK_ERROR_RETURN_RET_LOG(ret != AV_ERR_OK, 1, "Config failed, ret: %{public}d", ret);
     return 0;
diff --git a/services/camera_service/src/hcapture_session.cpp b/services/camera_service/src/hcapture_session.cpp
index 22b408c46..14aaa87c4 100644
--- a/services/camera_service/src/hcapture_session.cpp
+++ b/services/camera_service/src/hcapture_session.cpp
@@ -649,11 +649,14 @@ int32_t HCaptureSession::GetActiveColorSpace(ColorSpace& colorSpace)
     return CAMERA_OK;
 }
 
-int32_t HCaptureSession::SetColorSpace(ColorSpace colorSpace, ColorSpace captureColorSpace, bool isNeedUpdate)
+int32_t HCaptureSession::SetColorSpace(ColorSpace colorSpace, bool isNeedUpdate)
 {
+    MEDIA_INFO_LOG("HCaptureSession::SetColorSpace() colorSpace: %{public}d, isNeedUpdate: %{public}d",
+        colorSpace, isNeedUpdate);
     int32_t result = CAMERA_OK;
     stateMachine_.StateGuard(
-        [&result, this, &colorSpace, &captureColorSpace, &isNeedUpdate](CaptureSessionState currentState) {
+        [&result, this, &colorSpace, &isNeedUpdate](CaptureSessionState currentState) {
+            MEDIA_INFO_LOG("HCaptureSession::SetColorSpace() ColorSpace : %{public}d", colorSpace);
             if (!(currentState == CaptureSessionState::SESSION_CONFIG_INPROGRESS ||
                     currentState == CaptureSessionState::SESSION_CONFIG_COMMITTED ||
                     currentState == CaptureSessionState::SESSION_STARTED)) {
@@ -664,7 +667,7 @@ int32_t HCaptureSession::SetColorSpace(ColorSpace colorSpace, ColorSpace capture
 
             auto hStreamOperatorSptr = hStreamOperator_.promote();
             CHECK_ERROR_RETURN_LOG(hStreamOperatorSptr == nullptr, "hStreamOperator is nullptr");
-            result = hStreamOperatorSptr->SetColorSpace(colorSpace, captureColorSpace, isNeedUpdate);
+            result = hStreamOperatorSptr->SetColorSpace(colorSpace, isNeedUpdate);
             if (isNeedUpdate &&  result != CAMERA_OK) {
                 return;
             }
diff --git a/services/camera_service/src/hstream_capture.cpp b/services/camera_service/src/hstream_capture.cpp
index 9540f8dd8..0fc69d8a0 100644
--- a/services/camera_service/src/hstream_capture.cpp
+++ b/services/camera_service/src/hstream_capture.cpp
@@ -35,6 +35,7 @@
 #include "picture_interface.h"
 #include "hstream_operator_manager.h"
 #include "hstream_operator.h"
+#include "display/graphic/common/v1_0/cm_color_space.h"
 
 namespace OHOS {
 namespace CameraStandard {
@@ -92,7 +93,8 @@ void HStreamCapture::FullfillPictureExtendStreamInfos(StreamInfo_V1_1 &streamInf
         .type = static_cast<HDI::Camera::V1_1::ExtendedStreamInfoType>(HDI::Camera::V1_3::EXTENDED_STREAM_INFO_GAINMAP),
         .width = width_,
         .height = height_,
-        .format = format,
+        .format = format, // HDR:NV21 P3:NV21
+        .dataspace = dataSpace_, // HDR:BT2020_HLG_FULL P3:P3_FULL
         .bufferQueue = gainmapBufferQueue_,
     };
     HDI::Camera::V1_1::ExtendedStreamInfo deepExtendedStreamInfo = {
@@ -126,6 +128,7 @@ void HStreamCapture::FullfillPictureExtendStreamInfos(StreamInfo_V1_1 &streamInf
 void HStreamCapture::SetStreamInfo(StreamInfo_V1_1 &streamInfo)
 {
     HStreamCommon::SetStreamInfo(streamInfo);
+    MEDIA_INFO_LOG("HStreamCapture::SetStreamInfo streamId:%{public}d format:%{public}d", GetFwkStreamId(), format_);
     streamInfo.v1_0.intent_ = STILL_CAPTURE;
     if (format_ == OHOS_CAMERA_FORMAT_HEIC) {
         streamInfo.v1_0.encodeType_ =
@@ -137,14 +140,18 @@ void HStreamCapture::SetStreamInfo(StreamInfo_V1_1 &streamInfo)
         if (GetMode() != static_cast<int32_t>(HDI::Camera::V1_3::OperationMode::TIMELAPSE_PHOTO)) {
             FullfillPictureExtendStreamInfos(streamInfo, GRAPHIC_PIXEL_FMT_YCRCB_420_SP);
         }
+        if (dataSpace_ == CM_BT2020_HLG_FULL || dataSpace_ == CM_BT2020_HLG_LIMIT) {
+            streamInfo.v1_0.dataspace_ = CM_P3_FULL; // HDR photo need P3 for captureStream
+        } else if (dataSpace_ == CM_BT709_LIMIT) {
+            streamInfo.v1_0.dataspace_ = CM_SRGB_FULL; // video session need SRGB for captureStream
+        }
     } else {
         streamInfo.v1_0.encodeType_ = ENCODE_TYPE_JPEG;
     }
     if (rawDeliverySwitch_) {
         MEDIA_INFO_LOG("HStreamCapture::SetStreamInfo Set DNG info, streamId:%{public}d", GetFwkStreamId());
         HDI::Camera::V1_1::ExtendedStreamInfo extendedStreamInfo = {
-            .type =
-                static_cast<HDI::Camera::V1_1::ExtendedStreamInfoType>(HDI::Camera::V1_3::EXTENDED_STREAM_INFO_RAW),
+            .type = static_cast<HDI::Camera::V1_1::ExtendedStreamInfoType>(HDI::Camera::V1_3::EXTENDED_STREAM_INFO_RAW),
             .width = width_,
             .height = height_,
             .format = streamInfo.v1_0.format_,
@@ -154,12 +161,15 @@ void HStreamCapture::SetStreamInfo(StreamInfo_V1_1 &streamInfo)
         streamInfo.extendedStreamInfos.push_back(extendedStreamInfo);
     }
     if (thumbnailSwitch_) {
+        MEDIA_DEBUG_LOG("HStreamCapture::SetStreamInfo Set thumbnail info, dataspace:%{public}d", dataSpace_);
+        int32_t pixelFormat = GRAPHIC_PIXEL_FMT_YCRCB_420_SP;
+        pixelFormat = dataSpace_ == CM_BT2020_HLG_FULL ? GRAPHIC_PIXEL_FMT_YCRCB_P010 : pixelFormat;
         HDI::Camera::V1_1::ExtendedStreamInfo extendedStreamInfo = {
             .type = HDI::Camera::V1_1::EXTENDED_STREAM_INFO_QUICK_THUMBNAIL,
             .width = 0,
             .height = 0,
-            .format = 0,
-            .dataspace = 0,
+            .format = pixelFormat, // HDR: YCRCB_P010 P3: nv21
+            .dataspace = dataSpace_, // HDR: BT2020_HLG_FULL P3: P3
             .bufferQueue = thumbnailBufferQueue_,
         };
         MEDIA_INFO_LOG("HStreamCapture::extendedStreamInfos_thumbnailSwitch_");
diff --git a/services/camera_service/src/hstream_common.cpp b/services/camera_service/src/hstream_common.cpp
index f529e350e..01b9c6825 100644
--- a/services/camera_service/src/hstream_common.cpp
+++ b/services/camera_service/src/hstream_common.cpp
@@ -84,8 +84,9 @@ HStreamCommon::HStreamCommon(
     callerToken_ = IPCSkeleton::GetCallingTokenID();
     const int32_t metaStreamId = -1;
     fwkStreamId_ = streamType == StreamType::METADATA ? metaStreamId : GenerateStreamId();
-    MEDIA_DEBUG_LOG(
-        "HStreamCommon Create streamId_ is %{public}d, streamType is:%{public}d", fwkStreamId_, streamType_);
+    MEDIA_DEBUG_LOG("HStreamCommon Create streamId:%{public}d type:%{public}d width:%{public}d height:%{public}d"
+                    " format:%{public}d ",
+        fwkStreamId_, streamType_,  width_, height_, format_);
 }
 
 HStreamCommon::~HStreamCommon()
@@ -175,11 +176,13 @@ void HStreamCommon::SetStreamInfo(StreamInfo_V1_1 &streamInfo)
     } else {
         MEDIA_ERR_LOG("HStreamCommon::SetStreamInfo find format error, pixelFormat use default format");
     }
-    MEDIA_DEBUG_LOG("HStreamCommon::SetStreamInfo pixelFormat is %{public}d", pixelFormat);
+    MEDIA_DEBUG_LOG("HStreamCommon::SetStreamInfo pixelFormat:%{public}d type:%{public}d colorSpace:%{public}d",
+        pixelFormat, streamType_, dataSpace_);
     streamInfo.v1_0.streamId_ = hdiStreamId_;
     streamInfo.v1_0.width_ = width_;
     streamInfo.v1_0.height_ = height_;
     streamInfo.v1_0.format_ = pixelFormat;
+    streamInfo.v1_0.dataspace_ = dataSpace_;
     streamInfo.v1_0.minFrameDuration_ = 0;
     streamInfo.v1_0.tunneledMode_ = true;
     {
@@ -191,8 +194,6 @@ void HStreamCommon::SetStreamInfo(StreamInfo_V1_1 &streamInfo)
             streamInfo.v1_0.bufferQueue_ = nullptr;
         }
     }
-    MEDIA_DEBUG_LOG("HStreamCommon::SetStreamInfo type %{public}d, dataSpace %{public}d", streamType_, dataSpace_);
-    streamInfo.v1_0.dataspace_ = dataSpace_;
     streamInfo.extendedStreamInfos = {};
 }
 
diff --git a/services/camera_service/src/hstream_operator.cpp b/services/camera_service/src/hstream_operator.cpp
index 26964e091..e8ec09990 100644
--- a/services/camera_service/src/hstream_operator.cpp
+++ b/services/camera_service/src/hstream_operator.cpp
@@ -106,9 +106,44 @@ int32_t HStreamOperator::Initialize(const uint32_t callerToken, int32_t opMode)
     opMode_ = opMode;
     MEDIA_INFO_LOG(
         "HStreamOperator::opMode_= %{public}d", opMode_);
+    InitDefaultColortSpace(static_cast<SceneMode>(opMode));
     return CAMERA_OK;
 }
 
+void HStreamOperator::InitDefaultColortSpace(SceneMode opMode)
+{
+    static const std::unordered_map<SceneMode, ColorSpace> colorSpaceMap = {
+        {SceneMode::NORMAL, ColorSpace::SRGB},
+        {SceneMode::CAPTURE, ColorSpace::SRGB},
+        {SceneMode::VIDEO, ColorSpace::BT2020_HLG_LIMIT},
+        {SceneMode::PORTRAIT, ColorSpace::DISPLAY_P3},
+        {SceneMode::NIGHT, ColorSpace::DISPLAY_P3},
+        {SceneMode::PROFESSIONAL, ColorSpace::DISPLAY_P3},
+        {SceneMode::SLOW_MOTION, ColorSpace::BT709_LIMIT},
+        {SceneMode::SCAN, ColorSpace::BT709_LIMIT},
+        {SceneMode::CAPTURE_MACRO, ColorSpace::DISPLAY_P3},
+        {SceneMode::VIDEO_MACRO, ColorSpace::BT2020_HLG_LIMIT},
+        {SceneMode::PROFESSIONAL_PHOTO, ColorSpace::DISPLAY_P3},
+        {SceneMode::PROFESSIONAL_VIDEO, ColorSpace::BT709_LIMIT},
+        {SceneMode::HIGH_FRAME_RATE, ColorSpace::BT709_LIMIT},
+        {SceneMode::HIGH_RES_PHOTO, ColorSpace::DISPLAY_P3},
+        {SceneMode::SECURE, ColorSpace::SRGB},
+        {SceneMode::QUICK_SHOT_PHOTO, ColorSpace::DISPLAY_P3},
+        {SceneMode::LIGHT_PAINTING, ColorSpace::DISPLAY_P3},
+        {SceneMode::PANORAMA_PHOTO, ColorSpace::DISPLAY_P3},
+        {SceneMode::TIMELAPSE_PHOTO, ColorSpace::DISPLAY_P3},
+        {SceneMode::APERTURE_VIDEO, ColorSpace::BT709_LIMIT},
+        {SceneMode::FLUORESCENCE_PHOTO, ColorSpace::DISPLAY_P3},
+    };
+    auto it = colorSpaceMap.find(opMode);
+    if (it != colorSpaceMap.end()) {
+        currColorSpace_ = it->second;
+    } else {
+        currColorSpace_ = ColorSpace::SRGB;
+    }
+    MEDIA_DEBUG_LOG("HStreamOperator::InitDefaultColortSpace colorSpace:%{public}d", currColorSpace_);
+}
+
 HStreamOperator::HStreamOperator()
 {
     pid_ = 0;
@@ -153,17 +188,20 @@ int32_t HStreamOperator::AddOutputStream(sptr<HStreamCommon> stream)
     CHECK_ERROR_RETURN_RET_LOG(
         stream->GetFwkStreamId() == STREAM_ID_UNSET && stream->GetStreamType() != StreamType::METADATA,
         CAMERA_INVALID_ARG, "HStreamOperator::AddOutputStream stream is released!");
+    // 应用当前扫码流未做降流规格处理
+    /*CHECK_ERROR_RETURN_RET_LOG(
+        !CheckFormat(currColorSpace_, static_cast<camera_format_t>(stream->format_), stream->GetStreamType()),
+        CAMERA_INVALID_ARG, "HCaptureSession::AddOutputStream format not match colorSpace!");*/
     bool isAddSuccess = streamContainer_.AddStream(stream);
     CHECK_ERROR_RETURN_RET_LOG(!isAddSuccess, CAMERA_INVALID_SESSION_CFG,
         "HStreamOperator::AddOutputStream add stream fail");
+    MEDIA_INFO_LOG("HCaptureSession::AddOutputStream stream colorSpace:%{public}d", currColorSpace_);
     if (stream->GetStreamType() == StreamType::CAPTURE) {
         auto captureStream = CastStream<HStreamCapture>(stream);
         captureStream->SetMode(opMode_);
-        captureStream->SetColorSpace(currCaptureColorSpace_);
         CameraDynamicLoader::LoadDynamiclibAsync(MEDIA_LIB_SO); // cache dynamiclib
-    } else {
-        stream->SetColorSpace(currColorSpace_);
     }
+    stream->SetColorSpace(currColorSpace_);
     return CAMERA_OK;
 }
 
@@ -564,7 +602,8 @@ void HStreamOperator::ExpandMovingPhotoRepeatStream()
                 audioCapturerSession_ = new AudioCapturerSession();
             }
             if (!taskManager_ && audioCapturerSession_) {
-                taskManager_ = new AvcodecTaskManager(audioCapturerSession_, VideoCodecType::VIDEO_ENCODE_TYPE_HEVC);
+                taskManager_ = new AvcodecTaskManager(audioCapturerSession_, VideoCodecType::VIDEO_ENCODE_TYPE_HEVC,
+                    currColorSpace_);
                 taskManager_->SetVideoBufferDuration(preCacheFrameCount_, postCacheFrameCount_);
             }
             if (!videoCache_ && taskManager_) {
@@ -688,28 +727,20 @@ int32_t HStreamOperator::GetActiveColorSpace(ColorSpace& colorSpace)
     return CAMERA_OK;
 }
 
-int32_t HStreamOperator::SetColorSpace(ColorSpace colorSpace, ColorSpace captureColorSpace, bool isNeedUpdate)
+int32_t HStreamOperator::SetColorSpace(ColorSpace colorSpace, bool isNeedUpdate)
 {
     int32_t result = CAMERA_OK;
-    CHECK_ERROR_RETURN_RET_LOG(colorSpace == currColorSpace_ && captureColorSpace == currCaptureColorSpace_, result,
+    CHECK_ERROR_RETURN_RET_LOG(colorSpace == currColorSpace_, result,
         "HStreamOperator::SetColorSpace() colorSpace no need to update.");
     currColorSpace_ = colorSpace;
-    currCaptureColorSpace_ = captureColorSpace;
+    MEDIA_INFO_LOG("HCaptureSession::SetColorSpace() old ColorSpace : %{public}d, old ColorSpace : %{public}d",
+        currColorSpace_, colorSpace);
     result = CheckIfColorSpaceMatchesFormat(colorSpace);
-    if (result != CAMERA_OK) {
-        if (isNeedUpdate) {
-            MEDIA_ERR_LOG("HStreamOperator::SetColorSpace() Failed, format and colorSpace not match.");
-            return result;
-        } else {
-            MEDIA_ERR_LOG(
-                "HStreamOperator::SetColorSpace() %{public}d, format and colorSpace: %{public}d not match.",
-                result, colorSpace);
-            currColorSpace_ = ColorSpace::BT709;
-        }
-    }
-    MEDIA_INFO_LOG("HStreamOperator::SetColorSpace() colorSpace: %{public}d, captureColorSpace: %{public}d, "
-        "isNeedUpdate: %{public}d", currColorSpace_, captureColorSpace, isNeedUpdate);
-    SetColorSpaceForStreams();
+    CHECK_ERROR_RETURN_RET_LOG(result != CAMERA_OK, result,
+        "HCaptureSession::SetColorSpace() Failed, format and colorSpace not match.");
+    CHECK_EXECUTE(!isNeedUpdate, SetColorSpaceForStreams());
+    MEDIA_INFO_LOG("HStreamOperator::SetColorSpace() colorSpace: %{public}d, isNeedUpdate: %{public}d",
+        currColorSpace_, isNeedUpdate);
     return result;
 }
 
@@ -718,11 +749,7 @@ void HStreamOperator::SetColorSpaceForStreams()
     auto streams = streamContainer_.GetAllStreams();
     for (auto& stream : streams) {
         MEDIA_DEBUG_LOG("HStreamOperator::SetColorSpaceForStreams() streams type %{public}d", stream->GetStreamType());
-        if (stream->GetStreamType() == StreamType::CAPTURE) {
-            stream->SetColorSpace(currCaptureColorSpace_);
-        } else {
-            stream->SetColorSpace(currColorSpace_);
-        }
+        stream->SetColorSpace(currColorSpace_);
     }
 }
 
@@ -774,34 +801,54 @@ int32_t HStreamOperator::UpdateStreamInfos(const std::shared_ptr<OHOS::Camera::C
 
 int32_t HStreamOperator::CheckIfColorSpaceMatchesFormat(ColorSpace colorSpace)
 {
-    if (!(colorSpace == ColorSpace::BT2020_HLG || colorSpace == ColorSpace::BT2020_PQ ||
-        colorSpace == ColorSpace::BT2020_HLG_LIMIT || colorSpace == ColorSpace::BT2020_PQ_LIMIT)) {
-        return CAMERA_OK;
-    }
-
+    MEDIA_DEBUG_LOG("HCaptureSession::CheckIfColorSpaceMatchesFormat start");
     // 选择BT2020，需要匹配10bit的format；若不匹配，返回error
     auto streams = streamContainer_.GetAllStreams();
     for (auto& curStream : streams) {
         if (!curStream) {
             continue;
         }
-        // 当前拍照流不支持BT2020，无需校验format
-        if (curStream->GetStreamType() != StreamType::REPEAT) {
-            continue;
-        }
         StreamInfo_V1_1 curStreamInfo;
-        curStream->SetStreamInfo(curStreamInfo);
-        MEDIA_INFO_LOG("HStreamOperator::CheckFormat, stream repeatType: %{public}d, format: %{public}d",
-            static_cast<HStreamRepeat*>(curStream.GetRefPtr())->GetRepeatStreamType(), curStreamInfo.v1_0.format_);
-        if (!(curStreamInfo.v1_0.format_ == OHOS::HDI::Display::Composer::V1_1::PIXEL_FMT_YCBCR_P010 ||
-            curStreamInfo.v1_0.format_ == OHOS::HDI::Display::Composer::V1_1::PIXEL_FMT_YCRCB_P010)) {
-            MEDIA_ERR_LOG("HStreamOperator::CheckFormat, stream format not match");
+        bool result = CheckFormat(colorSpace, static_cast<camera_format_t>(curStreamInfo.v1_0.format_),
+            curStream->GetStreamType());
+        if (!result) {
             return CAMERA_OPERATION_NOT_ALLOWED;
         }
     }
     return CAMERA_OK;
 }
 
+bool HStreamOperator::CheckFormat(ColorSpace colorSpace, camera_format_t format, StreamType streamType)
+{
+    MEDIA_INFO_LOG("HStreamOperator::CheckFormat colorSpace:%{public}d, format:%{public}d, streamType:%{public}d",
+        colorSpace, format, streamType);
+    if (streamType == StreamType::CAPTURE) {
+        if (colorSpace == BT2020_HLG) {
+            if (format == OHOS_CAMERA_FORMAT_YCRCB_420_SP || format == OHOS_CAMERA_FORMAT_JPEG ||
+                format == OHOS_CAMERA_FORMAT_HEIC) {
+                return true;
+            } else {
+                return false;
+            }
+        }
+    } else if (streamType == StreamType::REPEAT) {
+        if (colorSpace == SRGB || colorSpace == DISPLAY_P3 || colorSpace == BT709_LIMIT) {
+            if (format == OHOS_CAMERA_FORMAT_YCRCB_420_SP) {
+                return true;
+            } else {
+                return false;
+            }
+        } else if (colorSpace == BT2020_HLG || colorSpace == BT2020_HLG_LIMIT) {
+            if (format == OHOS_CAMERA_FORMAT_YCRCB_P010) {
+                return true;
+            } else {
+                return false;
+            }
+        }
+    }
+    return true;
+}
+
 int32_t HStreamOperator::EnableMovingPhoto(const std::shared_ptr<OHOS::Camera::CameraMetadata>& settings,
     bool isEnable, int32_t sensorOritation)
 {
@@ -1570,6 +1617,9 @@ int32_t HStreamOperator::CreateStreams(std::vector<HDI::Camera::V1_1::StreamInfo
         MEDIA_INFO_LOG("HStreamOperator::CreateStreams streamOperator V1_1");
         for (auto streamInfo : streamInfos) {
             if (streamInfo.extendedStreamInfos.size() > 0) {
+                MEDIA_INFO_LOG("HCameraDevice::CreateStreams streamId:%{public}d width:%{public}d height:%{public}d"
+                    "format:%{public}d dataspace:%{public}d", streamInfo.v1_0.streamId_, streamInfo.v1_0.width_,
+                    streamInfo.v1_0.height_, streamInfo.v1_0.format_, streamInfo.v1_0.dataspace_);
                 MEDIA_INFO_LOG("HStreamOperator::CreateStreams streamOperator V1_1 type %{public}d",
                     streamInfo.extendedStreamInfos[0].type);
             }
diff --git a/test/fuzztest/avcodectaskmanager_fuzzer/avcodec_task_manager_fuzzer.cpp b/test/fuzztest/avcodectaskmanager_fuzzer/avcodec_task_manager_fuzzer.cpp
index 2511954a1..f16672b03 100644
--- a/test/fuzztest/avcodectaskmanager_fuzzer/avcodec_task_manager_fuzzer.cpp
+++ b/test/fuzztest/avcodectaskmanager_fuzzer/avcodec_task_manager_fuzzer.cpp
@@ -66,8 +66,9 @@ void AvcodecTaskManagerFuzzer::AvcodecTaskManagerFuzzTest()
     }
     sptr<AudioCapturerSession> session = new AudioCapturerSession();
     VideoCodecType type = VideoCodecType::VIDEO_ENCODE_TYPE_AVC;
+    ColorSpace colorSpace = ColorSpace::DISPLAY_P3;
     if (fuzz_ == nullptr) {
-        fuzz_ = std::make_shared<AvcodecTaskManager>(session, type);
+        fuzz_ = std::make_shared<AvcodecTaskManager>(session, type, colorSpace);
     }
     fuzz_->GetTaskManager();
     fuzz_->GetEncoderManager();
diff --git a/test/fuzztest/capturesession_fuzzer/capture_session_fuzzer.cpp b/test/fuzztest/capturesession_fuzzer/capture_session_fuzzer.cpp
index 2e90af96f..b476886a2 100644
--- a/test/fuzztest/capturesession_fuzzer/capture_session_fuzzer.cpp
+++ b/test/fuzztest/capturesession_fuzzer/capture_session_fuzzer.cpp
@@ -581,7 +581,6 @@ void TestAdd(sptr<CaptureSession> session, uint8_t *rawData, size_t size)
     pid_t pid = data.ReadInt32();
     session->CameraServerDied(pid);
     session->CreateCameraAbilityContainer();
-    session->SetDefaultColorSpace();
 }
 
 void TestOther3(sptr<CaptureSession> session, uint8_t *rawData, size_t size)
diff --git a/test/fuzztest/hcapturesession_fuzzer/hcapture_session_fuzzer.cpp b/test/fuzztest/hcapturesession_fuzzer/hcapture_session_fuzzer.cpp
index 0951657cb..f48c3ce1b 100644
--- a/test/fuzztest/hcapturesession_fuzzer/hcapture_session_fuzzer.cpp
+++ b/test/fuzztest/hcapturesession_fuzzer/hcapture_session_fuzzer.cpp
@@ -109,8 +109,7 @@ void HCaptureSessionFuzzer::HCaptureSessionFuzzTest1()
     ColorSpace getColorSpace;
     fuzz_->GetActiveColorSpace(getColorSpace);
     ColorSpace colorSpace = static_cast<ColorSpace>(callerToken % 23);
-    ColorSpace captureColorSpace = static_cast<ColorSpace>(callerToken % 23);
-    fuzz_->SetColorSpace(colorSpace, captureColorSpace, GetData<bool>());
+    fuzz_->SetColorSpace(colorSpace, GetData<bool>());
     fuzz_->GetopMode();
     std::vector<StreamInfo_V1_1> streamInfos;
     fuzz_->GetCurrentStreamInfos(streamInfos);
diff --git a/test/fuzztest/hstreamoperator_fuzzer/hstream_operator_fuzzer.cpp b/test/fuzztest/hstreamoperator_fuzzer/hstream_operator_fuzzer.cpp
index 74c04dc33..51993ce98 100644
--- a/test/fuzztest/hstreamoperator_fuzzer/hstream_operator_fuzzer.cpp
+++ b/test/fuzztest/hstreamoperator_fuzzer/hstream_operator_fuzzer.cpp
@@ -97,11 +97,10 @@ void HStreamOperatorFuzzer::HStreamOperatorFuzzTest()
     ColorSpace getColorSpace;
     fuzz_->GetActiveColorSpace(getColorSpace);
     ColorSpace colorSpace = static_cast<ColorSpace>(callerToken % 23);
-    ColorSpace captureColorSpace = static_cast<ColorSpace>(callerToken % 23);
-    fuzz_->SetColorSpace(colorSpace, captureColorSpace, GetData<bool>());
+    fuzz_->SetColorSpace(colorSpace, GetData<bool>());
     fuzz_->GetStreamOperator();
     std::vector<int32_t> results = {GetData<uint32_t>()};
-    fuzz_->ReleaseStreams(results);
+    fuzz_->ReleaseStreams();
     std::vector<HDI::Camera::V1_1::StreamInfo_V1_1> streamInfos;
     fuzz_->CreateStreams(streamInfos);
     std::shared_ptr<OHOS::Camera::CameraMetadata> settings;
-- 
2.45.2.huawei.7